#include <stdexcept>
#include <iostream>
#include <cstdlib>
#include "FileOutput.h"
#include "AudioFile.h"
#include "BatchFile.h"
#include "BestPath.h"
#include "CommandLineManager.h"
#include "ConfigurationDynamicDecoder.h"
#include "ConfigurationFeatures.h"
#include "DynamicNetworkX.h"
#include "DynamicDecoderX.h"
#include "NetworkBuilderX.h"
#include "FeatureExtractor.h"
#include "FileUtils.h"
#include "FillerManager.h"
#include "HMMManager.h"
#include "LexiconManager.h"
#include "LexUnitsFile.h"
#include "LMManager.h"
#include "PhoneSet.h"
#include "TimeUtils.h"

#include <iostream>// std::cout, std::hex, std::endl
#include <iomanip> // std::setiosflags

using namespace std;

#include <string>

using namespace Bavieca;

// main for the tool "dynamicdecoder"
int main(int argc, char *argv[]) {

	try {

		// (1) define command line parameters
		CommandLineManager commandLineManager("dynamicdecoder",SYSTEM_VERSION,SYSTEM_AUTHOR,SYSTEM_DATE);	
		commandLineManager.defineParameter("-cfg","configuration file",PARAMETER_TYPE_FILE,false);
		commandLineManager.defineParameter("-hyp","hypothesis file",PARAMETER_TYPE_FILE,false);
		commandLineManager.defineParameter("-bat","batch file with entries [rawFile/featureFile utteranceId]",
			PARAMETER_TYPE_FILE,false);
			
		// (2) process command line parameters
		if (commandLineManager.parseParameters(argc,argv) == false) {
			return -1;
		}
		
		// get command line parameters
		const char *strFileConfiguration = commandLineManager.getParameterValue("-cfg");
		const char *strFileControl = commandLineManager.getParameterValue("-bat");
		const char *strFileHypothesis = commandLineManager.getParameterValue("-hyp");
		
		// load the configuration file
		ConfigurationDynamicDecoder configuration(strFileConfiguration);
		configuration.load();
		
		// configuration.ConfigurationFile::print();		
		// get parameters from the configuration file
	
		// feature extraction
		const char *strFileConfigurationFeatures = 
			configuration.getStrParameterValue("feature.configurationFile");
		const char *strCepstralNormalizationMode =
			configuration.getStrParameterValue("feature.cepstralNormalization.mode");
		const char *strCepstralNormalizationMethod =
			configuration.getStrParameterValue("feature.cepstralNormalization.method");
		int iCepstralNormalizationBufferSize = 
			configuration.getIntParameterValue("feature.cepstralNormalization.bufferSize");
		float fWarpFactor = 1.0;
		if (configuration.isParameterSet("feature.warpFactor")) {
			fWarpFactor = atof(configuration.getParameterValue("feature.warpFactor"));
		}
		const char *strFileFeatureTransform = NULL;
		if (configuration.isParameterSet("feature.transformFile")) {
			strFileFeatureTransform = configuration.getParameterValue("feature.transformFile");
		}
			
		// phone set
		const char *strFilePhoneSet = 
			configuration.getStrParameterValue("phoneticSymbolSet.file");
		
		// acoustic models
		const char *strFileAcousticModels = 
			configuration.getStrParameterValue("acousticModels.file"); 
		
		// language model
		const char *strLanguageModelFile = 
			configuration.getStrParameterValue("languageModel.file"); 
		const char *strLanguageModelFormat = 
			configuration.getStrParameterValue("languageModel.format"); 
		const char *strLanguageModelType = 
			configuration.getStrParameterValue("languageModel.type"); 
		float fLanguageModelScalingFactor = 
			configuration.getFloatParameterValue("languageModel.scalingFactor"); 
		//bool bLanguageCrossUtterance = 
		//	configuration.getBoolParameterValue("languageModel.crossUtterance");
			
		// lexicon
		const char *strFileLexicon = 
			configuration.getStrParameterValue("lexicon.file"); 
			
		// insertion penalty
		float fInsertionPenaltyStandard = 
			configuration.getFloatParameterValue("insertionPenalty.standard"); 
		float fInsertionPenaltyFiller = 
			configuration.getFloatParameterValue("insertionPenalty.filler"); 
		const char *strFileInsertionPenaltyFiller = 
			configuration.getStrParameterValue("insertionPenalty.filler.file"); 
		
		// pruning parameters
		int iMaxActiveArcs = configuration.getIntParameterValue("pruning.maxActiveArcs");
		int iMaxActiveArcsWE = configuration.getIntParameterValue("pruning.maxActiveArcsWE");
		int iMaxActiveTokensArc = configuration.getIntParameterValue("pruning.maxActiveTokensArc");	
		float fBeamWidthArcs = configuration.getFloatParameterValue("pruning.likelihoodBeam");
		float fBeamWidthArcsWE = configuration.getFloatParameterValue("pruning.likelihoodBeamWE");
		float fBeamWidthTokensArc = configuration.getFloatParameterValue("pruning.likelihoodBeamTokensArc");
		
		// output lattice?
		bool bLatticeGeneration = configuration.isParameterSet("output.lattice.folder");	
		const char *strFolderLattices = NULL;
		int iMaxWordSequencesState = -1;
		if (bLatticeGeneration) {
			strFolderLattices = configuration.getStrParameterValue("output.lattice.folder"); 
			iMaxWordSequencesState = 
				configuration.getIntParameterValue("output.lattice.maxWordSequencesState");
		}
		
		// output features?
		bool bOutputFeatures = configuration.isParameterSet("output.features.folder");
		const char *strFolderFeatures = NULL;
		if (bOutputFeatures) {
			strFolderFeatures = configuration.getStrParameterValue("output.features.folder"); ;
		}
		
		// output alignment?
		bool bOutputAlignment = configuration.isParameterSet("output.alignment.folder");
		const char *strFolderAlignments = NULL;
		if (bOutputAlignment) {
			strFolderAlignments = configuration.getStrParameterValue("output.alignment.folder"); ;
		}
	
		// output audio?
		bool bOutputAudio = configuration.isParameterSet("output.audio.folder");
		const char *strFolderAudio = NULL;
		if (bOutputAudio) {
			strFolderAudio = configuration.getStrParameterValue("output.audio.folder");
		}
	
		// load the phone set
		PhoneSet phoneSet(strFilePhoneSet);
		phoneSet.load();
	
		// load the lexicon
		LexiconManager lexiconManager(strFileLexicon,&phoneSet); 
		lexiconManager.load();
		lexiconManager.attachLexUnitPenalties(fInsertionPenaltyStandard,fInsertionPenaltyFiller);
		
		FillerManager fillerManager(strFileInsertionPenaltyFiller);	
		fillerManager.load();
		fillerManager.attachInsertionPenaltyFillers(&lexiconManager);
		
		// load the feature configuration
		ConfigurationFeatures configurationFeatures(strFileConfigurationFeatures);
		configurationFeatures.load();
		
		// get the feature normalization mode and method
		int iCepstralNormalizationMode = FeatureExtractor::getNormalizationMode(strCepstralNormalizationMode);
		int iCepstralNormalizationMethod = FeatureExtractor::getNormalizationMethod(strCepstralNormalizationMethod);
		
		// create the feature extractor
		FeatureExtractor featureExtractor(&configurationFeatures,fWarpFactor,
			iCepstralNormalizationBufferSize,iCepstralNormalizationMode,iCepstralNormalizationMethod);
		featureExtractor.initialize();
	
		// load the feature transforms
		//VTransform vTransformFeatures;
		//if (strFileFeatureTransform) {
		//	BatchFile batchFile(strFileFeatureTransform,"transform");
		//	batchFile.load();
		//	for(unsigned int i=0 ; i < batchFile.size() ; ++i) {
		//		Transform *transform = new Transform();
		//		transform->load(batchFile.getField(i,0u));
		//		vTransformFeatures.push_back(transform);
		//	}	
		//}
			
		// load the HMMs used for the estimation
		HMMManager hmmManager(&phoneSet,HMM_PURPOSE_EVALUATION);
		hmmManager.load(strFileAcousticModels);
		hmmManager.initializeDecoding();
		
		// create the aligner object?
		//Viterbi *viterbi = NULL;
		//if (bOutputAlignment) {
		//	viterbi = new Viterbi(&phoneSet,&hmmManager,&lexiconManager);	
		//}
		
		// load the language model
		LMManager lmManager(&lexiconManager,
									strLanguageModelFile,
									strLanguageModelFormat,
									strLanguageModelType); 
		lmManager.load();
		
		NetworkBuilderX networkBuilder(&phoneSet,&hmmManager,&lexiconManager);
		
		// build the decoding network
		DynamicNetworkX *network = networkBuilder.build();
		if (!network) {
			BVC_ERROR << "unable to build the decoding network";
		}
	
		DynamicDecoderX decoder(&phoneSet,&hmmManager,&lexiconManager,
				&lmManager,fLanguageModelScalingFactor,network,iMaxActiveArcs,
				iMaxActiveArcsWE,iMaxActiveTokensArc,fBeamWidthArcs,fBeamWidthArcsWE,fBeamWidthTokensArc,
				bLatticeGeneration,iMaxWordSequencesState);
	
		// initialize the decoder
		decoder.initialize();
		
		double dTimeBegin = TimeUtils::getTimeMilliseconds();	
		
		double dLikelihoodTotal = 0.0;
		int iFeatureVectorsTotal = 0;
		
		// load the batch file
		BatchFile batchFile(strFileControl,"audio|id");
		batchFile.load();
		
		// (4) extract session-data
		VUtteranceData vUtteranceData;
		for(unsigned int iUtterance = 0 ; iUtterance < batchFile.size() ; ++iUtterance) {
		
			// load the raw audio
			int iSamples = -1;
			short int *sSamples = AudioFile::load(batchFile.getField(iUtterance,"audio"),&iSamples);
		
			UtteranceData utteranceData;
			utteranceData.samples.sSamples = sSamples;
			utteranceData.samples.iSamples = iSamples;
			utteranceData.mFeatures = NULL;
			vUtteranceData.push_back(utteranceData);
		}	
		
		// extract features
		featureExtractor.extractFeaturesSession(vUtteranceData,true);
		
		
		FileOutput fileHypothesis(strFileHypothesis,false);
		fileHypothesis.open();
		int iUtterance = 0;
		for(VUtteranceData::iterator it = vUtteranceData.begin() ; it != vUtteranceData.end() ; ++it, ++iUtterance) {
		
			const char *strUtteranceId = batchFile.getField(iUtterance,"id");
		
			cout << "processing utterance: " << strUtteranceId << endl;
			
			iFeatureVectorsTotal += it->mFeatures->getRows();
			Matrix<float> *mFeatures = it->mFeatures;
			
			if (hmmManager.getFeatureDim() != mFeatures->getCols()) {
				BVC_ERROR << "inconsistent feature dimensionality, HMMs: " << hmmManager.getFeatureDim() 
					<< ", features: " << mFeatures->getCols();
			}	
			
			decoder.beginUtterance();
			decoder.process(*mFeatures);
			
			// best path
			BestPath *bestPath = decoder.getBestPath();
			if (bestPath) {	
				// append the best path to a file (trn format)
				bestPath->write(fileHypothesis.getStream(),strUtteranceId);	
				bestPath->print(true);
				dLikelihoodTotal += bestPath->getPathScore();
			} else {
				cout << "no best path!!\n";
			}
			
			 
			
			decoder.endUtterance();	
			
			// clean-up
			if (bestPath) {
				delete bestPath;
			}	
			delete [] it->samples.sSamples;
			delete it->mFeatures;
		}
		fileHypothesis.close();
		
		double dTimeEnd = TimeUtils::getTimeMilliseconds();
		double dTimeSeconds = (dTimeEnd-dTimeBegin)/1000.0;
		double dRTF = dTimeSeconds/(((float)iFeatureVectorsTotal)/100.0);
		
		BVC_INFORMATION << "- summary ------------------------------------";
		BVC_INFORMATION << "# utterances: " << iUtterance << " speech time: " << FLT(8,2) << 
			((float)iFeatureVectorsTotal)/100.0 << " seconds";
		BVC_INFORMATION << "decoding time: " << FLT(8,2) << dTimeSeconds << " seconds (RTF: " << 
			FLT(5,2) << dRTF << ")";
		BVC_INFORMATION << "likelihood: " << FLT(12,4) << dLikelihoodTotal << " (per frame: " << 
			FLT(8,4) << dLikelihoodTotal/((float)iFeatureVectorsTotal) << ")";
		BVC_INFORMATION << "----------------------------------------------";
		
		// uninitialize the decoder
		decoder.uninitialize();
		
		delete network;
		//if (bOutputAlignment) {
		//	delete viterbi;
		//}
	} 
	catch (std::runtime_error &e) {
	
		std::cerr << e.what() << std::endl;
		return -1;
	}	
	
	return 0;
}
